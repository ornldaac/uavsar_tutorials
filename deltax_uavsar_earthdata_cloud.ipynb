{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5334c8d0",
   "metadata": {},
   "source": [
    "# Delta-X UAVSAR Workflow in NASA EarthData Cloud\n",
    "Delta-X Uninhabited Aerial Vehicle Synthetic Aperture Radar (UAVSAR) datasets are available through NASA's Earthdata Cloud. NASA Earthdata on Cloud is always free and accessible via either HTTPS or direct [S3](https://aws.amazon.com/s3/) bucket access. With direct S3 access, you can bring your \\\"code to the data\\\", making your processing faster and scalable. Direct S3 access to NASA Earthdata on Cloud is only available if your Amazon Web Services ([AWS](https://aws.amazon.com/)) instance is set up in the `us-west-2` region. If you are new to the Earthdata Cloud, these NASA Earthdata [primers](https://www.earthdata.nasa.gov/learn/webinars-and-tutorials/cloud-primer-amazon-web-services) and [tutorials](https://www.earthdata.nasa.gov/learn/webinars-and-tutorials/how-cloud-earth-scientists) are good resources to get you started.\n",
    "\n",
    "To access a Juypter Notebook on [AWS EC2](https://aws.amazon.com/ec2/) instance:,\n",
    "\n",
    "1. On the AWS EC2 instance, start Juypter Notebook on port 8888 with the 'no-browser' parameter: `jupyter notebook --no-browser --port=8888`\n",
    "1. On your local machine, forward port 8000 to the remote port 8888 : `ssh -i my-key-pair.pem -L 8000:localhost:8888 my-instance-user-name@my-instance-IPv6-address`\n",
    "1. Now, the Jupyter Notebook can be accessed at `http://localhost:8000` in your local browser.\n",
    "\n",
    "**Important**: [NASA Earthdata Login (EDL)](https://urs.earthdata.nasa.gov/) is required to obtain the S3 temporary credentials and direct access S3 objects bucket. First, set up NASA Earthdata Login authentication using a `.netrc` file. Please refer to the instructions here: https://wiki.earthdata.nasa.gov/display/EL/How+To+Access+Data+With+cURL+And+Wget.\n",
    "\n",
    "## Delta-X UAVSAR Datasets\n",
    "ORNL DAAC has published following UAVSAR or UAVSAR-derived datasets collected for the Delta-X project.\n",
    "\n",
    "**Delta-X:**\n",
    "- UAVSAR L1 Single Look Complex (SLC) Stack Products, MRD, Louisiana, 2021. https://doi.org/10.3334/ORNLDAAC/1984\n",
    "- UAVSAR L1B Interferometric Products, MRD, Louisiana, 2021. https://doi.org/10.3334/ORNLDAAC/1979\n",
    "- UAVSAR L2 Interferometric Products, MRD, Louisiana, 2021. ORNL DAAC, Oak Ridge, Tennessee, USA. https://doi.org/10.3334/ORNLDAAC/2057\n",
    "- UAVSAR Level 3 Geocoded InSAR Derived Water Level Changes, LA,USA, 2021. https://doi.org/10.3334/ORNLDAAC/2058\n",
    "\n",
    "**Pre-Delta-X:**\n",
    "- L1 UAVSAR Single Look Complex and Interferograms, MRD, LA, USA, 2016. https://doi.org/10.3334/ORNLDAAC/1816\n",
    "- UAVSAR-derived Water Level Change Maps, Atchafalaya Basin, LA, USA, 2016. https://doi.org/10.3334/ORNLDAAC/1823\n",
    "- UAVSAR Georeferenced Channel Maps, Atchafalaya Basin, LA, USA, 2016. https://doi.org/10.3334/ORNLDAAC/1954\n",
    "\n",
    "In this tutorial we will read a Single Look Complex (SLC) image and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b183b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python modules\n",
    "import requests\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd910937",
   "metadata": {},
   "source": [
    "#### Data File Information\n",
    "This dataset contains UAVSAR Level 1 (L1) Single Look Complex (SLC) stack products for Delta-X flight lines.\n",
    "This L1 dataset is intended for users who are familiar with data from synthetic aperture radar, especially products from UAVSAR (https://uavsar.jpl.nasa.gov/). Contact UAVSAR for detailed information on how to interpret the files (https://uavsar.jpl.nasa.gov/cgi-bin/contact.pl).\n",
    "\n",
    "These L1 data contain slant range single look complex (SLC), latitude/longitude/height, look vector, doppler, and metadata files. The data are provided in SLC stack format (*.slc) with associated annotation (*.ann), latitude-longitude-height (*.llh), look vector (*.lkv), and Doppler centroid-slant range (*.dop) files.  The single look complex (SLC) stacks are in the HH, HV, VH, and VV polarizations. The same area was sampled at approximately 30-minute intervals. The SLCs are not corrected for residual baseline (BU).\n",
    "\n",
    "- Spatial Coverage:  Atchafalaya River and Terrebonne Basins in southern Louisiana\n",
    "- Spatial Resolution: 0.8m (along- flight-line) by 1.7 m (slant range, along line-of-sight (LOS))\n",
    "- Temporal Coverage:  2021-03-27 to 2021-04-18 and 2021-09-05 to 2021-09-13\n",
    "- Temporal Resolution: estimates at 30-minute intervals\n",
    "- File naming convention:\n",
    "    - The SLC (*.slc) and annotation (*.ann) files are named according to the UAVSAR standard product file naming convention. Each SLC and annotation file name is in the following format:\n",
    "    - {site name}_{line ID}_{flight ID}_{data take counter}_{acquisition date}_{band}{steering}{polarization}_{stack_number}_ {baseline correction}_{segment number}_{downsample factor}.slc\n",
    "    - {site name}_{line ID}_{flight ID}_{data take counter}_{acquisition date}_{band}{steering}{polarization}_{stack_number}_ {baseline correction}.ann\n",
    "    - The latitude-longitude-height (*.llh) files and look vector (*.lkv) files are named following the standard format:\n",
    "    - {site name}_{line ID}_{stack number}_{baseline correction}_{segment number}_{downsample factor}.llh or .lkv\n",
    "    - The Doppler centroid versus slant range (*.dop) files are named:\n",
    "    - {site name}_{line ID}_{stack number}_{baseline correction}.dop\n",
    "    - For all files, \n",
    "    - site name = \"atchaf\", \"eterre\" or \"wterre\"; 6-character alphanumeric site name assigned to the UAVSAR flight line.\n",
    "    - line ID = 5-character flight line ID assigned to the UAVSAR flight line (Table 2, Fig 3). The first 3 characters are the aircraft heading in degrees from North, and the last 2 characters are an alphanumeric counter chosen to ensure uniqueness of the ID.\n",
    "    - acquisition date = in format of YYMMDD, encoded as YY = the last two digits of the year, MM = month, DD = day of month, in UTC.\n",
    "\n",
    "## Search for UAVSAR SLC granules and retrieve S3 links\n",
    "Let's define a function that searches NASA's Common Metadata Repository ([CMR](https://cmr.earthdata.nasa.gov/search)) API to search and find the granules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdaab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_cmr(doi: str):\n",
    "    # CMR API base url\n",
    "    cmrurl='https://cmr.earthdata.nasa.gov/search/' \n",
    "    # doi search to get concept_id\n",
    "    doisearch = f'{cmrurl}collections.json?doi={doi}'\n",
    "    concept_id = requests.get(doisearch).json()['feed']['entry'][0]['id']\n",
    "\n",
    "    page_num = 1\n",
    "    page_size = 2000 # CMR page size limit\n",
    "    s3_arr = []\n",
    "\n",
    "    while True:\n",
    "         # defining parameters\n",
    "        cmr_param = {\n",
    "            \"collection_concept_id\": concept_id, \n",
    "            \"page_size\": page_size,\n",
    "            \"page_num\": page_num,\n",
    "        }\n",
    "\n",
    "        granulesearch = f'{cmrurl}granules.json'\n",
    "        r = requests.post(granulesearch, data=cmr_param)\n",
    "        r.raise_for_status()\n",
    "        granules = r.json()['feed']['entry']\n",
    "        if granules:\n",
    "            for g in granules:\n",
    "                # Get s3 links\n",
    "                for links in g['links']:\n",
    "                    if links['href'].startswith('s3://'):\n",
    "                        s3_arr.append(links['href'])\n",
    "\n",
    "            page_num += 1\n",
    "        else: \n",
    "            break\n",
    "            \n",
    "    return s3_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf824be0",
   "metadata": {},
   "source": [
    "The above python function search_cmr takes the dataset DOI and returns the dataset granules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0422cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi = '10.3334/ORNLDAAC/1984'# DOI of UAVSAR L1 SLC prodcut\n",
    "\n",
    "granule_arr = search_cmr(doi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42146d87",
   "metadata": {},
   "source": [
    "The granule_arr contains a list of s3 granule links, starting with `s3://`. We are interested in granule starting with `wterre_34202_21028_017_210407_L090VV_02_BU`. Let's print all these files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a373f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "granule_sub = []\n",
    "for g in granule_arr:\n",
    "    if g.split('/')[-1].startswith(\"wterre_34202_21028_017_210407_L090VV_02_BU\"):\n",
    "        granule_sub.append(g)\n",
    "print(granule_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb72ae",
   "metadata": {},
   "source": [
    "## Setup S3 Credentials and S3FS\n",
    "A temporary S3 Credentials is needed for read-only, same-region, direct access to S3 objects on the Earthdata cloud. Each of the DAACs has its own endpoint. More information about S3 credentials for ORNL DAAC is available at: https://data.ornldaac.earthdata.nasa.gov/s3credentialsREADME.\n",
    "\n",
    "We will now retrieve the credentials for ORNL DAAC data access. These credentials are temporary and currently valid for one hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python function to get s3 credentials\n",
    "def get_s3credentials(daac: str):\n",
    "    # DAAC S3 Credentials Endpoint\n",
    "    earthadata_s3 = f\"https://data.{daac}.earthdata.nasa.gov/s3credentials\"\n",
    "    r = requests.get(earthadata_s3)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "# get s3 credentials\n",
    "s3credentials = get_s3credentials(\"ornldaac\")\n",
    "# print expiration datetime\n",
    "print(f'The S3 credentials will expire on {s3credentials[\"expiration\"]} UTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06b3879",
   "metadata": {},
   "source": [
    "We will use [S3Fs](https://s3fs.readthedocs.io/), Pythonic file interface to S3 for file-system style access. Alternatively, you can use [Boto3](https://aws.amazon.com/sdk-for-python/), AWS Software Development Kit (SDK) for Python. We will pass S3 credentials to S3Fs class S3FileSystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45150592",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_s3 = s3fs.S3FileSystem(anon=False, \n",
    "                          key=s3credentials['accessKeyId'], \n",
    "                          secret=s3credentials['secretAccessKey'], \n",
    "                          token=s3credentials['sessionToken'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e148cbd",
   "metadata": {},
   "source": [
    "# Read and print the annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d69b43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# open the image annotation file\n",
    "ann_file = granule_sub[2]\n",
    "with fs_s3.open(ann_file, mode='r') as fh:\n",
    "    print(fh.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3249dc0f",
   "metadata": {},
   "source": [
    "## Read SLC image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c980e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read SLC image. \n",
    "\n",
    "seg1 = granule_sub[1]\n",
    "seg2 = granule_sub[0]\n",
    "\n",
    "# Download files\n",
    "# fs_s3.download(seg1, seg1.split('/')[-1])\n",
    "# fs_s3.download(seg2, seg2.split('/')[-1])\n",
    "\n",
    "# # Segment 1\n",
    "# cols_s1 = 9900\n",
    "# rows_s1 = 66664  \n",
    "# ds = np.memmap(seg1.split('/')[-1], dtype=np.complex64)\n",
    "# slc_seg1 = ds.reshape(rows_s1, cols_s1) ## multi-band example\n",
    "# ds = None\n",
    "# # Extract backscatter and phase\n",
    "# backscatter_seg1 = np.abs(slc_seg1)\n",
    "# phase_seg_1 = np.angle(slc_seg1)\n",
    "\n",
    "# Segment 2\n",
    "cols_s2 = 9900\n",
    "rows_s2 = 55408  \n",
    "ds = np.memmap(seg2.split('/')[-1], dtype=np.complex64)\n",
    "slc_seg2 = ds.reshape(rows_s2, cols_s2) ## multi-band example\n",
    "ds = None\n",
    "# Extract backscatter and phase\n",
    "backscatter_seg2 = np.abs(slc_seg2)\n",
    "phase_seg_2 = np.angle(slc_seg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a8747d",
   "metadata": {},
   "source": [
    "## Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "# # display backscatter of the slc\n",
    "# ax = fig.add_subplot(1,4,1)\n",
    "# cax = ax.imshow(backscatter_seg1, vmin=0.05, vmax=0.35, cmap='gray')\n",
    "# ax.set_title(\"backscatter segment1\")\n",
    "# cbar = fig.colorbar(cax, orientation='vertical')\n",
    "# #display phase of the slc\n",
    "# ax = fig.add_subplot(1,4,2)\n",
    "# cax = ax.imshow(phase_seg_1, cmap='hsv')\n",
    "# ax.set_title(\"phase segment1\")\n",
    "# cbar = fig.colorbar(cax, orientation='vertical')\n",
    "# display backscatter of the slc\n",
    "ax = fig.add_subplot(1,4,1)\n",
    "cax = ax.imshow(backscatter_seg2, vmin=0.05, vmax=0.35, cmap='gray')\n",
    "ax.set_title(\"backscatter segment2\")\n",
    "cbar = fig.colorbar(cax, orientation='vertical')\n",
    "#display phase of the slc\n",
    "ax = fig.add_subplot(1,4,2)\n",
    "cax = ax.imshow(phase_seg_2, cmap='hsv')\n",
    "ax.set_title(\"phase segment2\")\n",
    "cbar = fig.colorbar(cax, orientation='vertical')\n",
    "\n",
    "plt.show()\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593fe52f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
